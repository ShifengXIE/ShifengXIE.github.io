---
layout: page
permalink: /publications/index.html
title: Publications
---

## Publications

### Journal & Conference Papers

- **Xie, S.**, Yuan, R., Rossi, S., Hannagan, T.  
  *The Initialization Determines Whether In‑Context Learning Is Gradient Descent.*  
  Transactions on Machine Learning Research (TMLR), 2025.  

- **Xie, S.**, Redko, I., Feofanov, V., Alonso, M., Odonnat, A., Zhang, J., Palpanas, T.  
  *CauKer: Classification Time Series Foundation Models Can Be Pretrained on Synthetic Data Only.*  
  ICML 2025 Workshop on Foundation Models for Structured Data (Best Time Series Paper), 2025.  
  [arXiv](https://arxiv.org/abs/2508.02879)

- **Xie, S.**, Giraldo, J. H.  
  *Subgraph Gaussian Embedding Contrast for Self‑Supervised Graph Representation Learning.*  
  ECML‑PKDD 2025.  

- **Xie, S.**, Giraldo, J. H.  
  *Variational Graph Contrastive Learning.*  
  NeurIPS 2024 Workshop on Self‑Supervised Learning – Theory and Practice, 2024.  
  [View Paper](https://openreview.net/forum?id=vo99uctEaA)

- **Xie, S.**, Liu, Y., Shuai, W.  
  *FTUnet: Feature Transferred U‑Net for Single HDR Image Reconstruction.*  
  ACM Multimedia Asia (MMA), 2023 – Oral Presentation.  
  [View Paper](https://dl.acm.org/doi/10.1145/3595916.3626431)

- **Xie, S.**, Zhu, S.  
  *Feasibility Study of Intelligent Healthcare Based on Digital Twin and Data Mining.*  
  International Conference on Computer Information Science and Artificial Intelligence (CISAI), 2021.  
  [View Paper](https://ieeexplore.ieee.org/document/9719314)

### Patents

- **Neural Network Parameter Diffusion** – Xie, S., Yuan, R., Rossi, S., Hannagan, T.  
  Utilizes autoencoders and latent diffusion to compress and generate experts within mixture‑of‑experts models.

- **Permutation Symmetries Applied to DeepSeek Mixture of Experts Language Models** – Xie, S., Yuan, R., Rossi, S., Hannagan, T.  
  Introduces a novel weight permutation symmetry for aligning experts in GLU‑based MoE architectures, enabling efficient compression, fine‑tuning and merging for models like DeepSeek‑MoE‑16B and Qwen1.5‑MoE‑A2.7B.

### Reviewer & Service

- Reviewer for **NeurIPS 2024 Workshop on Compression**, **COLM 2025**, and **NeurIPS 2025**.
